% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/count_tokens.R
\name{get_token_count}
\alias{get_token_count}
\title{Count tokens in a text string}
\usage{
get_token_count(text, model_name = "BAAI/bge-large-en-v1.5", tokenizer = NULL)
}
\arguments{
\item{text}{Character string. The text to tokenize.}

\item{model_name}{Character string. Name of the pretrained tokenizer model to
load (e.g., "BAAI/bge-large-en-v1.5"). Only used if \code{tokenizer} is NULL.
Default is "BAAI/bge-large-en-v1.5".}

\item{tokenizer}{Optional. A pre-loaded tokenizer object from the \code{tok}
package. If provided, this takes precedence over \code{model_name}. Use this
for better performance when calling the function multiple times.}
}
\value{
Integer. The number of tokens in the text.
}
\description{
Calculates the number of tokens in a text string using a specified tokenizer.
Useful for understanding text length in tokens rather than characters,
particularly important for transformer models with token limits.
}
\examples{
\dontrun{
# Simple usage - single text string
get_token_count("Hello, how are you today?")

# Use a different model
get_token_count("Some text", model_name = "bert-base-uncased")

# For better performance with multiple calls: load tokenizer once
tokenizer_bge <- tok::tokenizer$from_pretrained("BAAI/bge-large-en-v1.5")
get_token_count("First text", tokenizer = tokenizer_bge)
get_token_count("Second text", tokenizer = tokenizer_bge)

# Use with dataframes
library(dplyr)
df <- df \%>\%
  mutate(token_count = purrr::map_int(text_column, get_token_count))

# Or with a pre-loaded tokenizer for efficiency
tokenizer_bge <- tok::tokenizer$from_pretrained("BAAI/bge-large-en-v1.5")
df <- df \%>\%
  mutate(bge_tokens = purrr::map_int(text_column,
                                     ~get_token_count(.x, tokenizer = tokenizer_bge)))
}

}
